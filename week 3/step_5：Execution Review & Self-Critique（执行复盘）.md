ç›®æ ‡ä¸€å¥è¯ï¼š

ğŸ‘‰ ä»»åŠ¡å®Œæˆåï¼ŒAgent ä¸åªæ˜¯ç»“æŸï¼Œ

ğŸ‘‰ è€Œæ˜¯ æ€»ç»“ç»éªŒ â†’ æç‚¼è§„å¾‹ â†’ åå“ºä¸‹ä¸€æ¬¡æ‰§è¡Œ

è¿™æ˜¯ Agent ä»
â€œèƒ½å®Œæˆä»»åŠ¡â€ â†’ â€œä¸‹æ¬¡åšå¾—æ›´å¥½â€ çš„å…³é”®ã€‚

## ä¸€ã€ä¸ºä»€ä¹ˆå¿…é¡»åš Execution Reviewï¼Ÿ

ç›®å‰ä¸ºæ­¢ï¼Œä½ å·²ç»æœ‰ï¼š

+ Planning / Re-planning

+ Plan-aware Memory

+ Tool Affinity Learning

ä½†å°‘äº†ä¸€æ­¥ï¼š

**æŠŠâ€œå‘ç”Ÿè¿‡çš„äº‹â€å˜æˆâ€œå¯å¤ç”¨çš„ç»éªŒâ€**

å¦åˆ™ï¼š

+ å­¦ä¹ æ˜¯éšå¼çš„ã€ä¸å¯è§£é‡Šçš„

+ äººæ— æ³•ç†è§£ Agent ä¸ºä»€ä¹ˆå˜â€œèªæ˜â€

+ æ— æ³•äººå·¥å¹²é¢„æˆ–è°ƒå‚

## äºŒã€Execution Review çš„å·¥ç¨‹å®šä½

âš ï¸ éå¸¸é‡è¦ï¼š

Review â‰  å†æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡
Review = ç¦»çº¿åæ€ï¼ˆOffline Reasoningï¼‰

å®ƒå‘ç”Ÿåœ¨ï¼š

```
Agent DONE ä¹‹å
```

## ä¸‰ã€Review çš„è¾“å…¥ä¸è¾“å‡ºï¼ˆå…ˆæƒ³æ¸…æ¥šï¼‰

è¾“å…¥ï¼ˆç³»ç»Ÿæä¾›ï¼‰

+ åŸå§‹ Task

+ Final Planï¼ˆå« versionï¼‰

+ æ¯ä¸ª Step çš„ï¼š

  + æˆåŠŸ / å¤±è´¥

  + ä½¿ç”¨çš„å·¥å…·

  + é‡è¯•æ¬¡æ•°

+ Tool Affinity å½“å‰çŠ¶æ€

è¾“å‡ºï¼ˆç»“æ„åŒ–ï¼‰

1. å“ªäº› Step åšå¾—å¥½

2. å“ªäº› Step æœ‰é—®é¢˜ï¼ˆåŸå› ï¼‰

3. å·¥å…·é€‰æ‹©æ˜¯å¦åˆç†

4. ä¸‹æ¬¡æ‰§è¡Œçš„æ”¹è¿›å»ºè®®

## å››ã€Review æ•°æ®ç»“æ„ï¼ˆå…³é”®ï¼‰

```review.py```

```python
from dataclasses import dataclass
from typing import List

@dataclass
class StepReview:
    step_id: int
    description: str
    success: bool
    notes: str

@dataclass
class ExecutionReview:
    task: str
    plan_version: int
    step_reviews: List[StepReview]
    overall_summary: str
    improvement_suggestions: List[str]
```

## äº”ã€Review Generatorï¼ˆæ¨¡å‹åªè´Ÿè´£â€œåæ€â€ï¼‰

```reviewer.py```

```python
class ExecutionReviewer:
    def __init__(self, llm):
        self.llm = llm

    def review(self, task, plan, memory) -> ExecutionReview:
        prompt = f"""
You are reviewing an agent execution.

Task:
{task}

Plan (version {plan.version}):
"""        

        for step in plan.steps:
            step_mem = memory.steps.get(step.id)
            prompt += f"\nStep [{step.id}] {step.description}\n"
            if step_mem:
                prompt += f"- Actions: {step_mem.actions}\n"
                prompt += f"- Errors: {step_mem.errors}\n"
            else:
                prompt += "- No data\n"

        prompt += """
Provide:
1. Step-by-step evaluation (success/failure + reason)
2. Overall execution summary
3. Concrete improvement suggestions for future runs

Respond in clear bullet points.
"""

        output = self.llm.call([
            {"role": "system", "content": prompt}
        ])

        # æ•™å­¦ç‰ˆï¼šè¿™é‡Œä¸åšå¤æ‚è§£æï¼Œç›´æ¥å­˜æ–‡æœ¬
        return ExecutionReview(
            task=task,
            plan_version=plan.version,
            step_reviews=[],
            overall_summary=output,
            improvement_suggestions=[]
        )
```

ğŸ‘‰ å…³é”®ç‚¹

+ Review ä¸è°ƒç”¨å·¥å…·

+ Review ä¸å½±å“å½“å‰æ‰§è¡Œ

+ Review æ˜¯â€œäº‹åæ™ºèƒ½â€

## å…­ã€æŠŠ Review æ¥å…¥ Agentï¼ˆéå¸¸ç®€å•ï¼‰

```agent.py``` åœ¨ DONE æ—¶åŠ å…¥ï¼š

```python
from reviewer import ExecutionReviewer
```


åœ¨ ```__init__```ï¼š

```python
self.reviewer = ExecutionReviewer(self.llm)
```


åœ¨å®Œæˆä»»åŠ¡åï¼š

```python
print("\nğŸ§¾ Execution Review:")
review = self.reviewer.review(
    task,
    self.plan,
    self.memory
)
print(review.overall_summary)
```

## ä¸ƒã€å¦‚ä½•â€œçœŸæ­£ç”¨ä¸Šâ€ Reviewï¼ˆå·¥ç¨‹å…³é”®ï¼‰

**æ–¹å¼ 1ï¸âƒ£ äººå·¥æŸ¥çœ‹ï¼ˆæœ€å¸¸è§ï¼‰**

+ ç”¨äºè°ƒ Prompt / Rule / Tool

**æ–¹å¼ 2ï¸âƒ£ åŠè‡ªåŠ¨**

+ äººå·¥æŠŠ Review ä¸­çš„å»ºè®®è½¬ä¸ºï¼š

  + æ–° Router è§„åˆ™
  
  + æ–° Tool Affinity åˆå§‹åŒ–å€¼

**æ–¹å¼ 3ï¸âƒ£ å…¨è‡ªåŠ¨ï¼ˆé«˜çº§ï¼‰**

+ æå– Review ä¸­çš„ï¼š

  + â€œcalculator åœ¨ math æ­¥éª¤æˆåŠŸç‡é«˜â€

+ è‡ªåŠ¨å†™å…¥ Affinity Store

âš ï¸ çœŸæ­£ç”Ÿäº§ç³»ç»Ÿé€šå¸¸ 2ï¸âƒ£ + 3ï¸âƒ£ æ··åˆ

## å…«ã€ä½ ç°åœ¨æ‹¥æœ‰çš„ Agent èƒ½åŠ›å…¨æ™¯

åˆ° ç¬¬ 3 å‘¨ç»“æŸï¼Œä½ å·²ç»å®Œæ•´å®ç°äº†ï¼š

ğŸ§  æ€è€ƒ

+ ReAct

+ Planning

+ Re-planning

ğŸ§­ å†³ç­–

+ Tool Proposal

+ Ranking

+ Tool Affinity Learning

ğŸ§  è®°å¿†

+ Plan-aware Memory

+ Execution Logs

**ğŸ” ç¨³å®šæ€§**

+ Retry

+ Error Recovery

ğŸ“ˆ è¿›åŒ–

Execution Review

Self-Critique

è¿™æ˜¯ çœŸæ­£æ„ä¹‰ä¸Šçš„ Agent ç³»ç»Ÿ
