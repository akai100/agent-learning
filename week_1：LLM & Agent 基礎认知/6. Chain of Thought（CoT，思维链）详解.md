## 1. Chain of Thought 的核心定义与本质

**1. 核心定义**

Chain of Thought 是一种**自然语言提示范式**，通过在提示词中加入**示例的分步推理过程**（而非仅给 “问题 - 答案” 对），引导模型在生成答案前，先输出清晰的推理步骤链，最终得到更准确的结果。

**2. 本质**

模型本身不具备 “真正的逻辑推理能力”，CoT 的本质是**激活模型训练数据中存储的隐性推理模式**—— 通过示例的推理步骤 “唤醒” 模型对应的知识片段，
让模型按人类的推理逻辑拼接这些片段，形成可追溯的推理链，从而降低复杂任务中的错误率。

**3. 与直接输出的对比**

+ 直接输出

  + 特点

    无推理步骤，直接给结果，复杂任务易出错

  + 示例

    输入：3+5×2-4=？

    模型输出：12（错误，未遵循先乘后加）

+ CoT 输出

  + 特点

    先分步推理，再给结果，可追溯、准确率高

  + 示例

    输入：3+5×2-4=？请分步计算

    模型输出：

    Thought 1：先计算乘法部分，5×2=10

    Thought 2：再按从左到右计算加法，3+10=13

    Thought 3：最后计算减法，13-4=9

    答案：9（正确）

## 2. 核心优势

**1. 提升复杂任务表现**

对需要多步骤推理的任务效果显著，包括数学计算、逻辑推理、代码调试、常识问答、多文档整合等。

**2. 推理过程可追溯**

模型输出的推理链能清晰展示每一步的思考逻辑，便于人类排查错误（比如哪一步数学计算出错、哪一步逻辑推导偏差）。

**3. 无需额外训练**

作为提示词技术，无需对模型进行微调或重新训练，仅通过修改输入格式即可生效，适配所有大语言模型（GPT、LLaMA、文心一言等）。

**4. 降低 “跳跃式错误”**

避免模型直接从问题跳到错误答案，通过分步推导减少 “一步错、步步错” 的连锁反应。


## 3. 主要类型

根据应用场景和提示方式的不同，CoT 主要分为 3 种核心类型，覆盖从基础到复杂的任务需求：

**1. 基础 CoT(Few-Shot CoT, 少样本思维链）**

这是最常用的类型，在提示词中提供 2-5 个 “问题 - 推理链 - 答案” 的示例，引导模型模仿示例的推理逻辑解决新问题。

**示例（数学计算任务）**

```
示例1：
问题：小明有5个苹果，妈妈又给了他3个，他送给小红2个，小明现在有几个苹果？
推理步骤：
1.  初始苹果数：5个
2.  妈妈给了3个后，数量变为：5+3=8个
3.  送给小红2个后，剩余数量：8-2=6个
答案：6

示例2：
问题：书架上有10本书，借出去4本，又买来7本，书架现在有几本书？
推理步骤：
1.  初始书本数：10本
2.  借出去4本后，数量变为：10-4=6本
3.  买来7本后，最终数量：6+7=13本
答案：13

新问题：
问题：商店里有20瓶饮料，卖出8瓶，又进货12瓶，商店现在有几瓶饮料？
请按照上述示例分步推理，再给出答案。
```

**2. Zero-Shot CoT（零样本思维链）**

无需提供任何示例，仅通过自然语言指令引导模型分步推理（常用指令如 “请分步思考”“请先说明推理过程，再给出答案”“让我们一步一步来解决这个问题”），适用于简单任务或无法获取示例的场景。

**示例（逻辑推理任务）**

```
问题：所有的猫都会爬树，小白是一只猫，小白会爬树吗？
请一步一步思考，先分析已知条件，再得出结论。
```

**3. CoT 变体（进阶类型，针对复杂任务）**

为应对更复杂的任务（如多轮推理、多模态任务、超长文本推理），衍生出多种 CoT 变体：

+ Self-Consistency（自一致性 CoT）

  让模型生成多条不同的推理链，最终通过投票选择出现次数最多的答案，进一步提升准确率。

+ Tree of Thought（ToT，思维树）

  在 CoT 基础上增加 “分支探索” 和 “回溯”，模型会评估每一步推理的合理性，若发现错误则回溯重新推导，适用于需要试错的复杂任务（如解谜、代码优化）

+ Multimodal CoT（多模态思维链）

  将文字推理与图像、音频等模态结合，比如先描述图像内容，再基于描述进行逻辑推导（如 “先识别图片中的物体，再计算物体数量”）。

## 4. 适用场景与非适用场景

**1. 高适配场景（效果显著）**

+ 数学计算

  小学算术、代数、几何证明、统计分析等（如 “计算 768×8/3 的结果并向上取整”）

+ 逻辑推理

  三段论推理、真假判断、排列组合、解谜等

+ 代码开发与调试

  代码编写思路拆解、Bug 排查、代码优化分步说明等（如 “分步说明如何用 PyTorch 实现 GLU 网络”）。

+ 常识与专业知识问答

  需要多步骤整合知识的问题（如 “为什么冬天湖面会结冰，而海水不易结冰？请分步解释”）。

+ 多步骤任务拆解

  复杂任务的流程规划（如 “请分步说明如何搭建一个简单的 Python Web 服务器”）

**2. 低适配场景（效果有限）**

+ 简单直接任务

  无需推理的信息提取、简单分类、文本润色等（如 “提取这句话的主语”“将这句话改为书面语”）。

+ 创意生成任务

  诗歌创作、故事写作、广告文案等（过度分步推理会限制创意，导致内容生硬）

+ 事实性记忆任务

  单纯的信息背诵（如 “中国的首都是哪里”），直接输出即可，无需推理链。

## 5. 关键技巧

1. 推理步骤要细化

   引导模型将复杂问题拆分为 “小而可解” 的步骤，避免步骤跳跃（比如数学计算要明确 “先乘除后加减”，逻辑推理要明确 “已知条件→推导过程→结论”）。

2. 示例要贴合任务

   Few-Shot CoT 的示例需与新问题属于同一领域、同一难度，示例的推理风格要统一（比如都是 “分步计算” 或 “分步分析”）。

3. 明确格式要求

   在提示词中明确要求模型输出 “推理步骤” 和 “最终答案”，可指定格式（如 “先写推理步骤，用数字编号，最后用‘答案：’引出结果”）。

4. 结合其他技术

   将 CoT 与 Prompt 结构化、上下文去污染等技术结合，比如先清理上下文干扰，再用 CoT 引导推理，效果更佳。
   
