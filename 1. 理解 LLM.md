LLM 的真实工作方式：

你只需要记住一句话：

**LLM = 在当前上下文里，预测“下一个 token 最可能是什么”**

这意味着：

+ ❌ 它不是在“思考真理”

+ ❌ 它不知道对错

+ ✅ 它只是在延续一种看起来“合理”的模式

这直接导致 3 个 Agent 核心问题

| 现象  | 原因            |
| --- | ------------- |
| 幻觉  | 没有“不知道”的概念    |
| 跑偏  | Context 被污染   |
| 不稳定 | Sampling 是概率的 |

👉 Agent 工程的本质：给模型加“护栏”

## 实战

🎯 目标

让你“感受到”模型的随机性。

**你要做的事**

+ 同一个 Prompt

+ 不同 temperature

+ 连续跑 10 次

观察：

+ 逻辑是否一致

+ 结论是否稳定

**你应该得出的结论**

Agent 不能靠一次回答

必须靠结构、循环和反馈
